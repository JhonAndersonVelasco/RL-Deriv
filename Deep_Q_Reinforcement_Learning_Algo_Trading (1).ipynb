{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG-YX6EtvxXP",
        "outputId": "9b2ddab8-3486-4cba-f60f-19b14cc11628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: alpaca-trade-api in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (2.3.0)\n",
            "Requirement already satisfied: PyYAML==6.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from alpaca-trade-api) (6.0)\n",
            "Requirement already satisfied: requests<3,>2 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from alpaca-trade-api) (2.28.2)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from alpaca-trade-api) (1.26.14)\n",
            "Requirement already satisfied: deprecation==2.1.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from alpaca-trade-api) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from alpaca-trade-api) (1.24.1)\n",
            "Requirement already satisfied: pandas>=0.18.1 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from alpaca-trade-api) (1.5.3)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from alpaca-trade-api) (1.5.0)\n",
            "Requirement already satisfied: msgpack==1.0.3 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from alpaca-trade-api) (1.0.3)\n",
            "Requirement already satisfied: aiohttp==3.8.1 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from alpaca-trade-api) (3.8.1)\n",
            "Requirement already satisfied: websockets<11,>=9.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from alpaca-trade-api) (10.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from aiohttp==3.8.1->alpaca-trade-api) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from aiohttp==3.8.1->alpaca-trade-api) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from aiohttp==3.8.1->alpaca-trade-api) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from aiohttp==3.8.1->alpaca-trade-api) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from aiohttp==3.8.1->alpaca-trade-api) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from aiohttp==3.8.1->alpaca-trade-api) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from aiohttp==3.8.1->alpaca-trade-api) (22.2.0)\n",
            "Requirement already satisfied: packaging in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from deprecation==2.1.0->alpaca-trade-api) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from pandas>=0.18.1->alpaca-trade-api) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from pandas>=0.18.1->alpaca-trade-api) (2022.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from requests<3,>2->alpaca-trade-api) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from requests<3,>2->alpaca-trade-api) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.18.1->alpaca-trade-api) (1.16.0)\n",
            "Requirement already satisfied: transformers in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (4.26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from transformers) (1.24.1)\n",
            "Requirement already satisfied: filelock in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: colorama in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: nltk in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: tqdm in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: click in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: colorama in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from click->nltk) (0.4.6)\n",
            "Requirement already satisfied: ipython in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (8.9.0)\n",
            "Requirement already satisfied: ipykernel in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (6.20.2)\n",
            "Collecting ipykernel\n",
            "  Using cached ipykernel-6.21.1-py3-none-any.whl (149 kB)\n",
            "Requirement already satisfied: matplotlib-inline in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipython) (0.1.6)\n",
            "Requirement already satisfied: jedi>=0.16 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipython) (0.18.2)\n",
            "Requirement already satisfied: pickleshare in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: pygments>=2.4.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipython) (2.14.0)\n",
            "Requirement already satisfied: traitlets>=5 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipython) (5.9.0)\n",
            "Requirement already satisfied: stack-data in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipython) (0.6.2)\n",
            "Requirement already satisfied: decorator in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipython) (5.1.1)\n",
            "Requirement already satisfied: colorama in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipython) (0.4.6)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipython) (3.0.36)\n",
            "Requirement already satisfied: backcall in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: tornado>=6.1 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipykernel) (6.2)\n",
            "Requirement already satisfied: nest-asyncio in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipykernel) (1.5.6)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipykernel) (1.6.6)\n",
            "Requirement already satisfied: packaging in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipykernel) (23.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipykernel) (8.0.2)\n",
            "Requirement already satisfied: comm>=0.1.1 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipykernel) (0.1.2)\n",
            "Requirement already satisfied: psutil in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipykernel) (5.9.4)\n",
            "Requirement already satisfied: pyzmq>=17 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipykernel) (25.0.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from ipykernel) (5.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
            "Requirement already satisfied: pywin32>=1.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (305)\n",
            "Requirement already satisfied: platformdirs>=2.5 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (2.6.2)\n",
            "Requirement already satisfied: wcwidth in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython) (0.2.6)\n",
            "Requirement already satisfied: pure-eval in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from stack-data->ipython) (0.2.2)\n",
            "Requirement already satisfied: executing>=1.2.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from stack-data->ipython) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from stack-data->ipython) (2.2.1)\n",
            "Requirement already satisfied: six in d:\\jhon\\desktop\\automl\\jupyter\\deep_q_reinforcement_learning_algo_trading\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n",
            "Installing collected packages: ipykernel\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 6.20.2\n",
            "    Uninstalling ipykernel-6.20.2:\n",
            "      Successfully uninstalled ipykernel-6.20.2\n",
            "Successfully installed ipykernel-6.21.1\n"
          ]
        }
      ],
      "source": [
        "!pip install alpaca-trade-api\n",
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!pip install ipython ipykernel --upgrade\n",
        "# !pip install pandas-profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yqOPvv-24bR-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Jhon\\Desktop\\AutoML\\Jupyter\\Deep_Q_Reinforcement_Learning_Algo_Trading\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Matplotlib is building the font cache; this may take a moment.\n"
          ]
        }
      ],
      "source": [
        "import alpaca_trade_api as alp\n",
        "from transformers import pipeline\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import sys, os, glob, random, time, datetime\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8yg00YT7xZl"
      },
      "source": [
        "Retrieve market data \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P0LAy-QH71En"
      },
      "outputs": [],
      "source": [
        "from alpaca_trade_api.rest import REST, TimeFrame, TimeFrameUnit\n",
        "# Secret key must to be changed if regenerating the key id\n",
        "api_key = 'CK9USH4DQYMWFNCW0ZZT'\n",
        "secret_key = 'M2QDBd6NV8lffBswZ6bI3tiLRTKFhpEHWRHY4LWQ'\n",
        "\n",
        "# api = REST(api_key, secret_key)\n",
        "# start_date = '2021-01-01'; end_date = '2022-01-01'\n",
        "# btc_bars = api.get_crypto_bars('BTCUSD', TimeFrame.Day, start_date, end_date).df # get_trades, get_quotes, ETHUSD\n",
        "# btc_bars\n",
        "# stock_choice = 'TSLA' # 'AAPL','AMD','AMZN','FB','GOOG','GOOGL','MSFT','NFLX','NVDA'\n",
        "# stock_bars = api.get_bars(stock_choice, TimeFrame.Day, start_date, end_date).df\n",
        "# stock_bars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz_qE_j0xaCb"
      },
      "source": [
        "Retrieve news data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U5qLyRVNxZBv"
      },
      "outputs": [],
      "source": [
        "from alpaca_trade_api.stream import Stream\n",
        "# For historic data use the REST class, for live data use the Stream class\n",
        "rest_client = REST(api_key, secret_key)\n",
        "stream_client = Stream(api_key, secret_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp-cF52-0Bf_"
      },
      "source": [
        "Transformer sentiment analysis using (HuggingFace) BERT network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "akgY-Bdw0KHo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Jhon\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Jhon\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
            "Downloading (…)lve/main/config.json: 100%|██████████| 933/933 [00:00<00:00, 104kB/s]\n",
            "d:\\Jhon\\Desktop\\AutoML\\Jupyter\\Deep_Q_Reinforcement_Learning_Algo_Trading\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Jhon\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Could not load model mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.roberta.modeling_tf_roberta.TFRobertaForSequenceClassification'>).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mstopwords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m model_names \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdistilbert-base-uncased-finetuned-sst-2-english\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mfiniteautomata/bertweet-base-sentiment-analysis\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mfhamborg/roberta-targeted-sentiment-classification-newsarticles\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mmrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m classifier \u001b[39m=\u001b[39m pipeline(\u001b[39m'\u001b[39;49m\u001b[39msentiment-analysis\u001b[39;49m\u001b[39m'\u001b[39;49m, model \u001b[39m=\u001b[39;49m model_names[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnews_data_processor\u001b[39m(news):\n\u001b[0;32m     13\u001b[0m   date \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(news\u001b[39m.\u001b[39mcreated_at)[:\u001b[39m10\u001b[39m]\n",
            "File \u001b[1;32md:\\Jhon\\Desktop\\AutoML\\Jupyter\\Deep_Q_Reinforcement_Learning_Algo_Trading\\lib\\site-packages\\transformers\\pipelines\\__init__.py:754\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[39m# Infer the framework from the model\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \u001b[39m# Forced if framework already defined, inferred if it's None\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[39m# Will load the correct model if possible\u001b[39;00m\n\u001b[0;32m    753\u001b[0m model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m--> 754\u001b[0m framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    755\u001b[0m     model,\n\u001b[0;32m    756\u001b[0m     model_classes\u001b[39m=\u001b[39mmodel_classes,\n\u001b[0;32m    757\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m    758\u001b[0m     framework\u001b[39m=\u001b[39mframework,\n\u001b[0;32m    759\u001b[0m     task\u001b[39m=\u001b[39mtask,\n\u001b[0;32m    760\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs,\n\u001b[0;32m    761\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    762\u001b[0m )\n\u001b[0;32m    764\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    765\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
            "File \u001b[1;32md:\\Jhon\\Desktop\\AutoML\\Jupyter\\Deep_Q_Reinforcement_Learning_Algo_Trading\\lib\\site-packages\\transformers\\pipelines\\base.py:266\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    265\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not load model \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m with any of the following classes: \u001b[39m\u001b[39m{\u001b[39;00mclass_tuple\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    268\u001b[0m framework \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mTF\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    269\u001b[0m \u001b[39mreturn\u001b[39;00m framework, model\n",
            "\u001b[1;31mValueError\u001b[0m: Could not load model mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.roberta.modeling_tf_roberta.TFRobertaForSequenceClassification'>)."
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "model_names = ['distilbert-base-uncased-finetuned-sst-2-english',\n",
        "               'finiteautomata/bertweet-base-sentiment-analysis',\n",
        "               'fhamborg/roberta-targeted-sentiment-classification-newsarticles',\n",
        "               'mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis']\n",
        "\n",
        "classifier = pipeline('sentiment-analysis', model = model_names[-1])\n",
        "\n",
        "def news_data_processor(news):\n",
        "  date = str(news.created_at)[:10]\n",
        "  summary = news.summary\n",
        "  headline = news.headline\n",
        "  text = headline + ' ' + summary\n",
        "  word_list = word_tokenize(text)\n",
        "  words = [word for word in word_list if word.isalpha()]\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  filtered_words = [w for w in words if not w in stop_words]\n",
        "\n",
        "  sentence = ' '.join(filtered_words)\n",
        "  sentiment = classifier(sentence)\n",
        "\n",
        "  return sentence, sentiment, date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-AfsgVbW2vJ2"
      },
      "outputs": [],
      "source": [
        "class DQRL_Trader():\n",
        "\n",
        "  def __init__(self, state_size, action_space=3):\n",
        "    self.state_size = state_size\n",
        "    self.action_space = action_space    \n",
        "    self.memory = deque(maxlen=1500)\n",
        "    self.inventory = []\n",
        "    self.n_data_inputs = 6 # open, open_avg_diff_5_days, open_avg_diff_5_days, portfolio_value, number_of_stocks, sentiment (=6 if including sentiment)\n",
        "\n",
        "    self.gamma = 0.95\n",
        "    self.epsilon = 1.0\n",
        "    self.epsilon_min = 0.1\n",
        "    self.epsilon_decay = 0.995\n",
        "    self.learning_rate = 0.001\n",
        "\n",
        "    self.model = self.model_builder()\n",
        "\n",
        "  def model_builder(self):\n",
        "    init = tf.keras.initializers.HeUniform(seed=1)\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(self.n_data_inputs,1), kernel_initializer=init),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_initializer=init),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_initializer=init),\n",
        "        # tf.keras.layers.Dense(64, activation='relu', kernel_initializer=init),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(self.action_space, activation='linear', kernel_initializer=init)\n",
        "    ])\n",
        "    model.compile(loss=tf.keras.losses.Huber(), optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate))\n",
        "    return model \n",
        "\n",
        "  def trade(self, state):\n",
        "    if random.random() <= self.epsilon:\n",
        "      return random.randrange(self.action_space)\n",
        "    else:\n",
        "      options = self.model.predict(state)\n",
        "      # print('options', options)\n",
        "    return np.argmax(options[0])\n",
        "\n",
        "  def batch_Q_learn(self, batch_size):\n",
        "    mini_batch = []\n",
        "    Mem = len(self.memory)\n",
        "    # print('len(self.memory) = ', Mem)\n",
        "    for i in range(Mem - batch_size + 1, Mem):\n",
        "      mini_batch.append(self.memory[i])\n",
        "\n",
        "    for state, action, reward, next_state, done in mini_batch:\n",
        "      target = reward\n",
        "      if not done:\n",
        "        target = reward + self.gamma * np.amax(self.model.predict(next_state))\n",
        "\n",
        "      target_func = self.model.predict(state)\n",
        "      # print('state ', state)\n",
        "      # print('action ', action)\n",
        "      target_func[0][action] = target\n",
        "      self.model.fit(state, target_func, epochs=1, verbose=0)\n",
        "\n",
        "      if self.epsilon > self.epsilon_min:\n",
        "        self.epsilon *= self.epsilon_decay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LChk2IAKKtKg"
      },
      "outputs": [],
      "source": [
        "def price_format(p):\n",
        "  return ('-$' if p<0 else '$') + '{0:.2f}'.format(abs(p))\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qbIECTSf229s"
      },
      "outputs": [],
      "source": [
        "# N-day state representation ending at time t\n",
        "def create_state(data, time_step, window_size, portfolio, n_stocks):\n",
        "  start_index = time_step - window_size + 1\n",
        "  data_window = data[start_index : time_step+1] if start_index >= 0 else (-start_index * [data[0]]) + list(data[0 : time_step+1])\n",
        "  # print(len(data_window), window_size)\n",
        "  state=[]\n",
        "  for i in range(len(data_window) -1):\n",
        "    indicators = sigmoid(data_window[i+1] - data_window[i]).flatten()\n",
        "    joint = [*indicators, portfolio, n_stocks]\n",
        "    state.append(joint)\n",
        "    # print(sigmoid(data_window[i+1] - data_window[i]))\n",
        "\n",
        "  return np.array(state).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GWumupswAW56"
      },
      "outputs": [
        {
          "ename": "HTTPError",
          "evalue": "403 Client Error: Forbidden for url: https://data.alpaca.markets/v2/stocks/TSLA/bars?timeframe=1Day&adjustment=raw&start=2020-01-01&end=2022-01-01",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m start_date \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m2020-01-01\u001b[39m\u001b[39m'\u001b[39m; end_date \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m2022-01-01\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      2\u001b[0m stock_choice \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTSLA\u001b[39m\u001b[39m'\u001b[39m \u001b[39m# 'AAPL','AMD','AMZN','FB','GOOG','GOOGL','MSFT','NFLX','NVDA'\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m stock_bars \u001b[39m=\u001b[39m rest_client\u001b[39m.\u001b[39;49mget_bars(stock_choice, TimeFrame\u001b[39m.\u001b[39;49mDay, start_date, end_date)\u001b[39m.\u001b[39mdf\n\u001b[0;32m      5\u001b[0m \u001b[39m# stream_client.subscribe_news(live_news_data, stock_choice)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# stream_client.run()\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_date_arr\u001b[39m(data):\n",
            "File \u001b[1;32md:\\Jhon\\Desktop\\AutoML\\Jupyter\\Deep_Q_Reinforcement_Learning_Algo_Trading\\lib\\site-packages\\alpaca_trade_api\\rest.py:714\u001b[0m, in \u001b[0;36mREST.get_bars\u001b[1;34m(self, symbol, timeframe, start, end, adjustment, limit, feed, asof)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_bars\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    705\u001b[0m              symbol: Union[\u001b[39mstr\u001b[39m, List[\u001b[39mstr\u001b[39m]],\n\u001b[0;32m    706\u001b[0m              timeframe: TimeFrame,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    712\u001b[0m              asof: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    713\u001b[0m              ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BarsV2:\n\u001b[1;32m--> 714\u001b[0m     bars \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_bars_iter(symbol,\n\u001b[0;32m    715\u001b[0m                                    timeframe,\n\u001b[0;32m    716\u001b[0m                                    start,\n\u001b[0;32m    717\u001b[0m                                    end,\n\u001b[0;32m    718\u001b[0m                                    adjustment,\n\u001b[0;32m    719\u001b[0m                                    limit,\n\u001b[0;32m    720\u001b[0m                                    feed\u001b[39m=\u001b[39;49mfeed,\n\u001b[0;32m    721\u001b[0m                                    asof\u001b[39m=\u001b[39;49masof,\n\u001b[0;32m    722\u001b[0m                                    raw\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[0;32m    723\u001b[0m     \u001b[39mreturn\u001b[39;00m BarsV2(bars)\n",
            "File \u001b[1;32md:\\Jhon\\Desktop\\AutoML\\Jupyter\\Deep_Q_Reinforcement_Learning_Algo_Trading\\lib\\site-packages\\alpaca_trade_api\\rest.py:698\u001b[0m, in \u001b[0;36mREST.get_bars_iter\u001b[1;34m(self, symbol, timeframe, start, end, adjustment, limit, feed, asof, raw)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_bars_iter\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    681\u001b[0m                   symbol: Union[\u001b[39mstr\u001b[39m, List[\u001b[39mstr\u001b[39m]],\n\u001b[0;32m    682\u001b[0m                   timeframe: TimeFrame,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    688\u001b[0m                   asof: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    689\u001b[0m                   raw\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BarIterator:\n\u001b[0;32m    690\u001b[0m     bars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_get(\u001b[39m'\u001b[39m\u001b[39mbars\u001b[39m\u001b[39m'\u001b[39m, symbol,\n\u001b[0;32m    691\u001b[0m                           timeframe\u001b[39m=\u001b[39mtimeframe,\n\u001b[0;32m    692\u001b[0m                           adjustment\u001b[39m=\u001b[39madjustment,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    696\u001b[0m                           feed\u001b[39m=\u001b[39mfeed,\n\u001b[0;32m    697\u001b[0m                           asof\u001b[39m=\u001b[39masof)\n\u001b[1;32m--> 698\u001b[0m     \u001b[39mfor\u001b[39;00m bar \u001b[39min\u001b[39;00m bars:\n\u001b[0;32m    699\u001b[0m         \u001b[39mif\u001b[39;00m raw:\n\u001b[0;32m    700\u001b[0m             \u001b[39myield\u001b[39;00m bar\n",
            "File \u001b[1;32md:\\Jhon\\Desktop\\AutoML\\Jupyter\\Deep_Q_Reinforcement_Learning_Algo_Trading\\lib\\site-packages\\alpaca_trade_api\\rest.py:585\u001b[0m, in \u001b[0;36mREST._data_get\u001b[1;34m(self, endpoint, symbol_or_symbols, api_version, endpoint_base, resp_grouped_by_symbol, page_limit, feed, asof, **kwargs)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[39mif\u001b[39;00m endpoint:\n\u001b[0;32m    584\u001b[0m     path \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mendpoint\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 585\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_get(path, data\u001b[39m=\u001b[39;49mdata, feed\u001b[39m=\u001b[39;49mfeed,\n\u001b[0;32m    586\u001b[0m                      api_version\u001b[39m=\u001b[39;49mapi_version)\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m resp_grouped_by_symbol:\n\u001b[0;32m    588\u001b[0m     k \u001b[39m=\u001b[39m endpoint \u001b[39mor\u001b[39;00m endpoint_base\n",
            "File \u001b[1;32md:\\Jhon\\Desktop\\AutoML\\Jupyter\\Deep_Q_Reinforcement_Learning_Algo_Trading\\lib\\site-packages\\alpaca_trade_api\\rest.py:270\u001b[0m, in \u001b[0;36mREST.data_get\u001b[1;34m(self, path, data, feed, api_version)\u001b[0m\n\u001b[0;32m    268\u001b[0m     data \u001b[39m=\u001b[39m data \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m    269\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mfeed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feed\n\u001b[1;32m--> 270\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    271\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, path, data, base_url\u001b[39m=\u001b[39;49mbase_url, api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[0;32m    272\u001b[0m )\n",
            "File \u001b[1;32md:\\Jhon\\Desktop\\AutoML\\Jupyter\\Deep_Q_Reinforcement_Learning_Algo_Trading\\lib\\site-packages\\alpaca_trade_api\\rest.py:213\u001b[0m, in \u001b[0;36mREST._request\u001b[1;34m(self, method, path, data, base_url, api_version)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39mwhile\u001b[39;00m retry \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    212\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_one_request(method, url, opts, retry)\n\u001b[0;32m    214\u001b[0m     \u001b[39mexcept\u001b[39;00m RetryException:\n\u001b[0;32m    215\u001b[0m         retry_wait \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry_wait\n",
            "File \u001b[1;32md:\\Jhon\\Desktop\\AutoML\\Jupyter\\Deep_Q_Reinforcement_Learning_Algo_Trading\\lib\\site-packages\\alpaca_trade_api\\rest.py:234\u001b[0m, in \u001b[0;36mREST._one_request\u001b[1;34m(self, method, url, opts, retry)\u001b[0m\n\u001b[0;32m    232\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39mrequest(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopts)\n\u001b[0;32m    233\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m     resp\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[0;32m    235\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m http_error:\n\u001b[0;32m    236\u001b[0m     \u001b[39m# retry if we hit Rate Limit\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39min\u001b[39;00m retry_codes \u001b[39mand\u001b[39;00m retry \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[1;32md:\\Jhon\\Desktop\\AutoML\\Jupyter\\Deep_Q_Reinforcement_Learning_Algo_Trading\\lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m     http_error_msg \u001b[39m=\u001b[39m (\n\u001b[0;32m   1017\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Server Error: \u001b[39m\u001b[39m{\u001b[39;00mreason\u001b[39m}\u001b[39;00m\u001b[39m for url: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m     )\n\u001b[0;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
            "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://data.alpaca.markets/v2/stocks/TSLA/bars?timeframe=1Day&adjustment=raw&start=2020-01-01&end=2022-01-01"
          ]
        }
      ],
      "source": [
        "start_date = '2020-01-01'; end_date = '2022-01-01'\n",
        "stock_choice = 'TSLA' # 'AAPL','AMD','AMZN','FB','GOOG','GOOGL','MSFT','NFLX','NVDA'\n",
        "stock_bars = rest_client.get_bars(stock_choice, TimeFrame.Day, start_date, end_date).df\n",
        "\n",
        "# stream_client.subscribe_news(live_news_data, stock_choice)\n",
        "# stream_client.run()\n",
        "\n",
        "def create_date_arr(data):\n",
        "  stock_date_list = []\n",
        "  for i in range(len(data)):\n",
        "    date_str = str(data.index[i])[:10]\n",
        "    stock_date_list.append(date_str)\n",
        "  return np.array(stock_date_list)\n",
        "\n",
        "stock_open = stock_bars['open']\n",
        "stock_dates = create_date_arr(stock_bars)\n",
        "# print(stock_dates)\n",
        "\n",
        "# Compute the difference between the opening price of a day with the mean opening price over a previous set of days e.g. 5 and 50\n",
        "def avg_open_diff(open_price_data, n_days, start_index):\n",
        "  # if start_index < n_days:\n",
        "  #   print('Beware the moving average difference in opening price is only computed over the last {} day(s), as opposed to {}.'.format(start_index, n_days))\n",
        "  if start_index < len(open_price_data):\n",
        "    start_price = open_price_data[start_index]\n",
        "    prior_avg_price = open_price_data[start_index-n_days : start_index].mean()\n",
        "    diff = start_price - prior_avg_price if start_index-n_days >= 0 else start_price - open_price_data[:start_index].mean()\n",
        "    return diff\n",
        "  else:\n",
        "    return IndexError('Failed to compute moving average difference: invalid request')\n",
        "\n",
        "def create_avg_diff_data(data, n):\n",
        "  stock_avg_diff_n = [0] # avg diff = 0 for first open price\n",
        "  for i in range(1, len(data)):\n",
        "    stock_avg_diff_n_i = avg_open_diff(data, n, i)\n",
        "    stock_avg_diff_n.append(stock_avg_diff_n_i)\n",
        "  return np.array(stock_avg_diff_n)\n",
        "\n",
        "stock_avg_diff_5 = create_avg_diff_data(stock_open, 5)\n",
        "stock_avg_diff_50 = create_avg_diff_data(stock_open, 50)\n",
        "\n",
        "stock_data = np.transpose([stock_open, stock_avg_diff_5, stock_avg_diff_50])#.astype(np.float16)\n",
        "\n",
        "news = rest_client.get_news(stock_choice, start_date, end_date, limit=10000)\n",
        "\n",
        "N_news = len(news)\n",
        "NEG, POS, NEU = 0, 0, 0\n",
        "news_data_arr = []\n",
        "news_dates = []\n",
        "for i in range(N_news):\n",
        "  article_text, sentim, news_date = news_data_processor(news[i])\n",
        "  if news_date in stock_dates:\n",
        "    # print(news_date)\n",
        "    sentim_label = sentim[0]['label']\n",
        "    sentim_score = float(sentim[0]['score'])\n",
        "    if sentim_label == 'negative':\n",
        "      score = sentim_score * -1\n",
        "      # NEG+=1\n",
        "    elif sentim_label == 'positive':\n",
        "      score = sentim_score\n",
        "      # POS+=1\n",
        "    elif sentim_label == 'neutral':\n",
        "      score = 0.0\n",
        "      # NEU+=1\n",
        "    news_data_arr.append([score, news_date])\n",
        "    news_dates.append(news_date)\n",
        "    # news_data_arr.insert(i, [article_text, sentim[0]['label'], sentim[0]['score'], news_date]) if reversing time ordering (as news data is read in from end -> start date)\n",
        "    # news_data_arr.append([article_text, sentim[0]['label'], sentim[0]['score'], news_date])\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "# print(NEG, POS, NEU)\n",
        "# print(news_data_arr)\n",
        "news_data_reverse = news_data_arr[::-1]\n",
        "news_dates_reverse_array = np.asarray(news_data_reverse)\n",
        "\n",
        "# Sort by date-time\n",
        "def sort_DT(data):\n",
        "  return sorted(data, key=lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
        "\n",
        "unique_sorted_news_dates = np.array(sort_DT(list(set(news_dates))))\n",
        "sentiment_scores = []\n",
        "for unique_date in unique_sorted_news_dates:\n",
        "  # print(unique_date)\n",
        "  date_indexes = np.where(unique_date == news_dates_reverse_array)[0]\n",
        "  # print(news_dates_reverse_array[index_,0])\n",
        "  float_scores = [float(i) for i in news_dates_reverse_array[date_indexes,0]]\n",
        "  avg_score = np.mean(float_scores)\n",
        "  sentiment_scores.append(avg_score)\n",
        "\n",
        "sentiment_scores = np.array(sentiment_scores)\n",
        "\n",
        "if len(stock_data) != len(sentiment_scores):\n",
        "  print('Error in processing sentiment scores/ start-end dates misaligned for news and market data')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4147Adrb_9R1"
      },
      "outputs": [],
      "source": [
        "stock_sentiment_data = np.hstack((stock_data, np.expand_dims(sentiment_scores, axis=1)))\n",
        "print(stock_sentiment_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fo5fUuqi1dr7"
      },
      "outputs": [],
      "source": [
        "window_size = 5 # days inbetween action e.g. buy/sell/sit\n",
        "epochs = 1000\n",
        "batch_size = 32\n",
        "data = stock_sentiment_data     # stock_data     \n",
        "N_data = len(data)-1\n",
        "\n",
        "trader = DQRL_Trader(window_size)\n",
        "trader.model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpZu4kfN_dPk"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "  print('Epoch {}/{} ...'.format(epoch+1, epochs))\n",
        "\n",
        "  # state = create_state(data, 0, window_size+1)\n",
        "  trader.inventory = []\n",
        "  total_profit = 0\n",
        "  n_stocks_owned = 10\n",
        "  initial_funds = 1000\n",
        "  portfolio_value = (n_stocks_owned * data[0][0]) + initial_funds\n",
        "  print('Initial portfolio value: {} | Number of stocks: {}'.format(price_format(portfolio_value), n_stocks_owned))\n",
        "\n",
        "  state = create_state(data, 0, window_size+1, portfolio_value, n_stocks_owned)\n",
        "  # print(state.shape)\n",
        "\n",
        "  for t in range(N_data):\n",
        "    action = trader.trade(state)\n",
        "    # next_state = create_state(data, t+1, window_size+1)\n",
        "    next_state = create_state(data, t+1, window_size+1, portfolio_value, n_stocks_owned)\n",
        "    # print(next_state.shape)\n",
        "    reward = 0\n",
        "\n",
        "    if portfolio_value < data[t][0] or n_stocks_owned == 0: # punish inability to buy/sell stock\n",
        "      reward = -10\n",
        "\n",
        "    if portfolio_value < data[t][0] and n_stocks_owned == 0: # huge penalty for bankcruptcy\n",
        "      reward = -100 \n",
        "\n",
        "    if action == 0: # punish repeated sitting over time\n",
        "      print('Sitting...')\n",
        "      reward = -0.1\n",
        "    \n",
        "    elif action == 1 and portfolio_value >= data[t][0]: # buy\n",
        "      n_stocks_owned += 1\n",
        "      portfolio_value -= data[t][0]\n",
        "      trader.inventory.append(data[t])\n",
        "      print('Trader bought a stock for {}'.format(price_format(data[t][0])))\n",
        "      print('Total portfolio value: {} | Number of stocks: {}'.format(price_format(portfolio_value), n_stocks_owned))\n",
        "\n",
        "    elif action == 2 and len(trader.inventory) > 0: # sell\n",
        "      bought_price = trader.inventory.pop(0)\n",
        "      n_stocks_owned -= 1\n",
        "      portfolio_value += data[t][0]\n",
        "      # print('bought_price: ', bought_price)\n",
        "      if data[t][0] - bought_price[0] > 0:\n",
        "        reward = 1\n",
        "      elif data[t][0] - bought_price[0] == 0:\n",
        "        reward = 0\n",
        "      else:\n",
        "        reward = -1\n",
        "\n",
        "      total_profit += data[t][0] - bought_price[0]\n",
        "      print('Trader sold one stock at {} | Transaction profit: {}'.format(price_format(data[t][0]), price_format(data[t][0] - bought_price[0])))\n",
        "      print('Total portfolio value: {} | Number of stocks: {}'.format(price_format(portfolio_value), n_stocks_owned))\n",
        "\n",
        "    done = True if t == N_data-1 else False\n",
        "\n",
        "    trader.memory.append([state, action, reward, next_state, done])\n",
        "    # print('memory', trader.memory)\n",
        "    state = next_state\n",
        "\n",
        "    if done:\n",
        "      print('\\n Total profit = {} \\n'.format(price_format(total_profit)))\n",
        "\n",
        "    if len(trader.memory) > batch_size:\n",
        "      trader.batch_Q_learn(batch_size)\n",
        "    else:\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gob_9-SiLnh7"
      },
      "outputs": [],
      "source": [
        "# state_data, action_data = [], []\n",
        "# for i in range(len(trader.memory)):\n",
        "#   state_data.append(np.squeeze(trader.memory[i][0]))\n",
        "#   action_data.append(np.squeeze(trader.memory[i][1]))  \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Deep_Q_Reinforcement_Learning_Algo_Trading.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Deep_Q_Reinforcement_Learning_Algo_Trading",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "ef86c4023f250e1f8d6aa49c986e7574a4f212aaaf8ab347c958da2e30b2e04e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
